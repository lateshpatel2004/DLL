# ------------------------------------------------------------
# Transfer learning on tf_flowers using VGG16 (detailed comments)
# ------------------------------------------------------------

import tensorflow_datasets as tfds     # convenient dataset loader
import tensorflow as tf                # core TensorFlow library
from tensorflow.keras.utils import to_categorical
import numpy as np
import matplotlib.pyplot as plt

# -------------------------
# 1) Load the tf_flowers dataset
# -------------------------
# We load the entire dataset into memory (batch_size=-1) so we get NumPy arrays/tensors.
# Note: for large datasets you should stream them with batches; tf_flowers is small enough to load fully.
print("[INFO] loading tf_flowers dataset...")
(train_images, train_labels), (test_images, test_labels) = tfds.load(
    "tf_flowers",
    split=["train[:70%]", "train[70%:]"],  # non-overlapping 70% train / 30% test split
    batch_size=-1,                         # return the full split as a single tensor
    as_supervised=True,                    # return (image, label) pairs
)

# The returned objects are `tf.Tensor`s. Convert to NumPy for some ops (optional).
train_images = np.array(train_images)
test_images  = np.array(test_images)
train_labels = np.array(train_labels)
test_labels  = np.array(test_labels)

# Quick sanity check: print shapes
print("train_images shape:", train_images.shape)   # (N_train, H, W, C)
print("test_images  shape:", test_images.shape)    # (N_test, H, W, C)
print("train_labels shape:", train_labels.shape)
print("test_labels shape:", test_labels.shape)

# -------------------------
# 2) Resize images to the input size expected by VGG16
# -------------------------
# VGG16 expects images of at least 32x32; common practice is 150x150 for transfer learning examples.
# We use tf.image.resize which works with NumPy arrays if wrapped with tf.convert_to_tensor.
train_images_resized = tf.image.resize(train_images, (150, 150)).numpy()
test_images_resized  = tf.image.resize(test_images,  (150, 150)).numpy()

print("After resizing - train_images_resized shape:", train_images_resized.shape)

# -------------------------
# 3) Convert integer labels to one-hot vectors
# -------------------------
# tf_flowers has 5 classes; convert labels like `2` -> [0,0,1,0,0]
num_classes = 5
train_labels_cat = to_categorical(train_labels, num_classes=num_classes)
test_labels_cat  = to_categorical(test_labels,  num_classes=num_classes)

# -------------------------
# 4) Preprocess inputs for VGG16
# -------------------------
# VGG16 expects images preprocessed with its `preprocess_input` helper:
# - converts RGB to BGR, centers each channel with ImageNet mean, etc.
from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input

# Convert pixel values from [0,255] to float and run VGG preprocessing
# preprocess_input expects float images in range 0..255
train_inputs = train_images_resized.astype('float32')
test_inputs  = test_images_resized.astype('float32')

train_inputs = preprocess_input(train_inputs)
test_inputs  = preprocess_input(test_inputs)

# -------------------------
# 5) Create the base VGG16 model (pretrained) and freeze it
# -------------------------
# include_top=False excludes the final classification head of VGG16 so we can attach our own layers.
base_model = VGG16(weights="imagenet", include_top=False, input_shape=(150, 150, 3))
base_model.trainable = False  # freeze convolutional base to keep pretrained weights

# Inspect the base model summary (optional)
base_model.summary()

# -------------------------
# 6) Build our top (classification head)
# -------------------------
from tensorflow.keras import layers, models

flatten_layer   = layers.Flatten()
dense_layer_1   = layers.Dense(50, activation='relu')
dense_layer_2   = layers.Dense(20, activation='relu')
prediction_layer= layers.Dense(num_classes, activation='softmax')

model = models.Sequential([
    base_model,         # pretrained feature extractor
    flatten_layer,      # flatten feature maps to vector
    dense_layer_1,      # dense layer to learn task-specific combinations
    dense_layer_2,      # another dense + non-linearity
    prediction_layer    # output probabilities for each flower class
])

# Print the full model architecture
model.summary()

# -------------------------
# 7) Compile the model
# -------------------------
# - Optimizer: Adam (good default)
# - Loss: categorical_crossentropy (we used one-hot labels)
# - Metrics: accuracy
model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy'],
)

# -------------------------
# 8) Train the model
# -------------------------
# We use `validation_split=0.2` which will carve 20% of the training set for validation.
# Note: since train_inputs is a NumPy array, Keras can perform this split automatically.
history = model.fit(
    train_inputs,          # NumPy array of training images
    train_labels_cat,      # corresponding one-hot labels
    epochs=10,
    validation_split=0.2,
    batch_size=32,
    shuffle=True
)

# -------------------------
# 9) Evaluate on the held-out test set
# -------------------------
loss, accuracy = model.evaluate(test_inputs, test_labels_cat, verbose=1)
print("Test Loss: {:.4f}  Test Accuracy: {:.2f}%".format(loss, accuracy * 100))

# -------------------------
# 10) Plot training history (accuracy and loss)
# -------------------------
plt.figure(figsize=(12, 4))

# Accuracy plot
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='train_accuracy')
plt.plot(history.history['val_accuracy'], label='val_accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(loc='lower right')

# Loss plot
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='train_loss')
plt.plot(history.history['val_loss'], label='val_loss')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(loc='upper right')

plt.tight_layout()
plt.show()
